<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>ML Papers | myliu6.ai</title>
<meta name="keywords" content="">
<meta name="description" content="AI Alignment
Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming
Anthropic (Jan 2025) https://arxiv.org/pdf/2501.18837

Alignment Faking in Large Language Models
Anthropic (Dec 2024) https://arxiv.org/pdf/2412.14093

Constitutional AI: Harmlessness from AI Feedback
Anthropic (Dec 2022) https://arxiv.org/pdf/2212.08073

Pre-training
DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model
DeepSeek (June 2024) https://arxiv.org/pdf/2405.04434

Reinforcement Learning
DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning
DeepSeek (Jan 2025) https://arxiv.org/pdf/2501.12948

DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models
DeepSeek (Apr 2024) https://arxiv.org/pdf/2401.06066
">
<meta name="author" content="Michael Liu">
<link rel="canonical" href="http://localhost:1313/posts/ml-papers/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.200e94311823bd018afe1f3f5162f5c79f4ff85f8364e1c10d47cb0a43c114da.css" integrity="sha256-IA6UMRgjvQGK/h8/UWL1x59P&#43;F&#43;DZOHBDUfLCkPBFNo=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/%3Clink%20/%20abs%20url%3E">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/ml-papers/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$']],
    displayMath: [['\\[', '\\]'], ['$$', '$$']],
    processEscapes: true,
    processEnvironments: true
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  },
  startup: {
    pageReady: () => {
      return MathJax.startup.defaultPageReady().then(() => {
        console.log('MathJax initial typesetting complete');
      });
    }
  },
  chtml: {
    fontURL: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2'
  }
};
</script>
<script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

    <link rel="stylesheet" href="/css/custom.css">
    <script src="/js/zoom.js"></script> 
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="myliu6.ai (Alt + H)">myliu6.ai</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      ML Papers
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2024-12-14 07:07:07 +0100 +0100'>December 14, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Michael Liu

</div>
  </header> <aside id="toc-container" class="toc-container wide">
<div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#ai-alignment" aria-label="AI Alignment">AI Alignment</a><ul>
                        
                <li>
                    <a href="#constitutional-classifiers-defending-against-universal-jailbreaks-across-thousands-of-hours-of-red-teaming" aria-label="Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming">Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming</a></li>
                <li>
                    <a href="#alignment-faking-in-large-language-models" aria-label="Alignment Faking in Large Language Models">Alignment Faking in Large Language Models</a></li>
                <li>
                    <a href="#constitutional-ai-harmlessness-from-ai-feedback" aria-label="Constitutional AI: Harmlessness from AI Feedback">Constitutional AI: Harmlessness from AI Feedback</a></li></ul>
                </li>
                <li>
                    <a href="#pre-training" aria-label="Pre-training">Pre-training</a><ul>
                        
                <li>
                    <a href="#deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model" aria-label="DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li></ul>
                </li>
                <li>
                    <a href="#reinforcement-learning" aria-label="Reinforcement Learning">Reinforcement Learning</a><ul>
                        
                <li>
                    <a href="#deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning" aria-label="DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning">DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</a></li>
                <li>
                    <a href="#deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models" aria-label="DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</a></li>
                <li>
                    <a href="#training-language-models-to-follow-instructions-with-human-feedback-instructgpt" aria-label="Training language models to follow instructions with human feedback (InstructGPT)">Training language models to follow instructions with human feedback (InstructGPT)</a></li>
                <li>
                    <a href="#playing-atari-with-deep-reinforcement-learning" aria-label="Playing Atari with Deep Reinforcement Learning">Playing Atari with Deep Reinforcement Learning</a></li></ul>
                </li>
                <li>
                    <a href="#inference" aria-label="Inference">Inference</a><ul>
                        
                <li>
                    <a href="#fast-inference-from-transformers-via-speculative-decoding" aria-label="Fast Inference from Transformers via Speculative Decoding">Fast Inference from Transformers via Speculative Decoding</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>

  <div class="post-content"><h1 id="ai-alignment">AI Alignment<a hidden class="anchor" aria-hidden="true" href="#ai-alignment">#</a></h1>
<h2 id="constitutional-classifiers-defending-against-universal-jailbreaks-across-thousands-of-hours-of-red-teaming">Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming<a hidden class="anchor" aria-hidden="true" href="#constitutional-classifiers-defending-against-universal-jailbreaks-across-thousands-of-hours-of-red-teaming">#</a></h2>
<p>Anthropic (Jan 2025) <a href="https://arxiv.org/pdf/2501.18837">https://arxiv.org/pdf/2501.18837</a>
<img src="/assets/images/ml-papers/constitutional-classifiers.png"></p>
<h2 id="alignment-faking-in-large-language-models">Alignment Faking in Large Language Models<a hidden class="anchor" aria-hidden="true" href="#alignment-faking-in-large-language-models">#</a></h2>
<p>Anthropic (Dec 2024) <a href="https://arxiv.org/pdf/2412.14093">https://arxiv.org/pdf/2412.14093</a>
<img src="/assets/images/ml-papers/alignment-faking.png"></p>
<h2 id="constitutional-ai-harmlessness-from-ai-feedback">Constitutional AI: Harmlessness from AI Feedback<a hidden class="anchor" aria-hidden="true" href="#constitutional-ai-harmlessness-from-ai-feedback">#</a></h2>
<p>Anthropic (Dec 2022) <a href="https://arxiv.org/pdf/2212.08073">https://arxiv.org/pdf/2212.08073</a>
<img src="/assets/images/ml-papers/constitutional-ai.png"></p>
<h1 id="pre-training">Pre-training<a hidden class="anchor" aria-hidden="true" href="#pre-training">#</a></h1>
<h2 id="deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model<a hidden class="anchor" aria-hidden="true" href="#deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model">#</a></h2>
<p>DeepSeek (June 2024) <a href="https://arxiv.org/pdf/2405.04434">https://arxiv.org/pdf/2405.04434</a>
<img src="/assets/images/ml-papers/deepseek-v2.png"></p>
<h1 id="reinforcement-learning">Reinforcement Learning<a hidden class="anchor" aria-hidden="true" href="#reinforcement-learning">#</a></h1>
<h2 id="deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning">DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning<a hidden class="anchor" aria-hidden="true" href="#deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning">#</a></h2>
<p>DeepSeek (Jan 2025) <a href="https://arxiv.org/pdf/2501.12948">https://arxiv.org/pdf/2501.12948</a>
<img src="/assets/images/ml-papers/deepseek-r1.png"></p>
<h2 id="deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models<a hidden class="anchor" aria-hidden="true" href="#deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models">#</a></h2>
<p>DeepSeek (Apr 2024) <a href="https://arxiv.org/pdf/2401.06066">https://arxiv.org/pdf/2401.06066</a>
<img src="/assets/images/ml-papers/grpo.png"></p>
<h2 id="training-language-models-to-follow-instructions-with-human-feedback-instructgpt">Training language models to follow instructions with human feedback (InstructGPT)<a hidden class="anchor" aria-hidden="true" href="#training-language-models-to-follow-instructions-with-human-feedback-instructgpt">#</a></h2>
<p>OpenAI (March 2022) <a href="https://arxiv.org/pdf/2203.02155">https://arxiv.org/pdf/2203.02155</a>
<img src="/assets/images/ml-papers/instruct-gpt.png"></p>
<h2 id="playing-atari-with-deep-reinforcement-learning">Playing Atari with Deep Reinforcement Learning<a hidden class="anchor" aria-hidden="true" href="#playing-atari-with-deep-reinforcement-learning">#</a></h2>
<p>DeepMind (December 2013) <a href="https://arxiv.org/pdf/1312.5602">https://arxiv.org/pdf/1312.5602</a></p>
<h1 id="inference">Inference<a hidden class="anchor" aria-hidden="true" href="#inference">#</a></h1>
<h2 id="fast-inference-from-transformers-via-speculative-decoding">Fast Inference from Transformers via Speculative Decoding<a hidden class="anchor" aria-hidden="true" href="#fast-inference-from-transformers-via-speculative-decoding">#</a></h2>
<p>Google (May 2023) <a href="https://arxiv.org/pdf/2211.17192">https://arxiv.org/pdf/2211.17192</a>
<img src="/assets/images/ml-papers/speculative-decoding.png"></p>


  </div>
  <div class="post-citation">
    <h1 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h1>
    <p><br>Cited as:</p>
    <blockquote>
      <p>Michael Liu. (Dec 2024). ML Papers. myliu6.ai. http://localhost:1313/posts/ml-papers/</p>
    </blockquote>
    <p>Or</p>
    <pre tabindex="0"><code>@article{ml-papers,
  title   = "ML Papers",
  author  = "Michael Liu",
  journal = "myliu6.ai",
  year    = "2024",
  month   = "Dec",
  url     = "http://localhost:1313/posts/ml-papers/"
}</code></pre>
  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">myliu6.ai</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
