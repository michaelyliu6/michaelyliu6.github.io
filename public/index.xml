<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ML&#39;s Blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on ML&#39;s Blog</description>
    <generator>Hugo -- 0.140.0</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Mar 2025 10:00:00 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Claude Plays Pokemon</title>
      <link>http://localhost:1313/posts/claude-plays-pokemon/</link>
      <pubDate>Mon, 03 Mar 2025 10:00:00 -0500</pubDate>
      <guid>http://localhost:1313/posts/claude-plays-pokemon/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: This blog post was written based on the initial Claude Plays Pokemon livestream. The implementation appears to have changed since this analysis was written with new tools and potentially new prompts. For the most up-to-date information, please refer to the latest livestream recordings.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;With the release of Claude 3.7 Sonnet, Anthropic also released a first of its kind benchmark: Claude playing Pokemon Red. Despite never being explicitly trained to play the game, Claude was still able to make progress through the game and even getting the Surge&amp;rsquo;s badge (the 3rd badge in the game). Having grown up deeply invested in playing the Pokemon series games, I have very fond and intense memories from playing the game, so I wanted to take a deep dive into Claude&amp;rsquo;s experience playing the game. In this post, I will be deep diving into the scaffolding of the system and the tools that help Claude play the game and analyze how well it does.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why &#34;real&#34; Reinforcement Learning will create the strongest technical moats</title>
      <link>http://localhost:1313/posts/rl-predictions/</link>
      <pubDate>Sun, 16 Feb 2025 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/rl-predictions/</guid>
      <description>&lt;p&gt;The AI landscape has undergone rapid shifts in recent years. While 2023-2024 saw the commoditization of pre-training and supervised fine-tuning, 2025 will mark the emergence of &amp;ldquo;real&amp;rdquo; Reinforcement Learning (RL) as the primary technical moat in AI development. Unlike pre-training, which focuses on learning statistical correlations from massive datasets, RL allows models to actively explore solution spaces and discover novel strategies that generalize beyond static training data.&lt;/p&gt;
&lt;h2 id=&#34;the-limitations-of-rlhf-and-the-promise-of-real-rl&#34;&gt;The Limitations of RLHF and the Promise of &amp;ldquo;Real&amp;rdquo; RL&lt;/h2&gt;
&lt;p&gt;Unlike RLHF (Reinforcement Learning from Human Feedback), which optimizes for human approval rather than actual task performance, genuine RL with sparse rewards will enable models to solve complex end-to-end tasks autonomously. RLHF is fundamentally limited because it optimizes for a proxy objective (what looks good to humans) rather than directly solving problems correctly. Furthermore, models quickly learn to game reward models when trained with RLHF for extended periods. In contrast, true RL with sparse rewards—similar to what powered AlphaGo&amp;rsquo;s breakthrough—will create significant competitive advantages for several reasons.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training Language Models with Reinforcement Learning from Human Feedback</title>
      <link>http://localhost:1313/posts/rlhf/</link>
      <pubDate>Sat, 15 Feb 2025 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/rlhf/</guid>
      <description>&lt;p&gt;Reinforcement Learning from Human Feedback (RLHF) is a technique used to fine-tune large language models (LLMs) to better align with human preferences. It involves training a reward model based on human feedback and then using reinforcement learning to optimize the LLM&amp;rsquo;s policy to maximize the reward.&lt;/p&gt;
&lt;p&gt;This process generally involves three key steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Supervised Fine-tuning (SFT):&lt;/strong&gt; An initial language model is fine-tuned on a dataset of high-quality demonstrations, where the model learns to imitate the provided examples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Toy Diffusion Model</title>
      <link>http://localhost:1313/posts/toy_diffusion_model/</link>
      <pubDate>Fri, 10 Jan 2025 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/toy_diffusion_model/</guid>
      <description>&lt;h2 id=&#34;what-even-is-diffusion&#34;&gt;What even is Diffusion?&lt;/h2&gt;
&lt;p&gt;Diffusion models approach generative modeling by mapping out probability distributions in high-dimensional spaces. Consider our dataset as a tiny sample from an enormous space of possible images. Our goal is to estimate which regions of this vast space have high probability according to our target distribution.&lt;/p&gt;
&lt;p&gt;The core insight of diffusion is that if we add Gaussian noise to an image from our distribution, the resulting noisy image typically becomes less likely to belong to that distribution. This is an empirical observation about human perception - a shoe with a small amount of noise still looks like a shoe, but becomes less recognizable as more noise is added.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ML Papers</title>
      <link>http://localhost:1313/posts/ml-papers/</link>
      <pubDate>Sat, 14 Dec 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/ml-papers/</guid>
      <description>&lt;h1 id=&#34;ai-alignment&#34;&gt;AI Alignment&lt;/h1&gt;
&lt;h2 id=&#34;constitutional-classifiers-defending-against-universal-jailbreaks-across-thousands-of-hours-of-red-teaming&#34;&gt;Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming&lt;/h2&gt;
&lt;p&gt;Anthropic (Jan 2025) &lt;a href=&#34;https://arxiv.org/pdf/2501.18837&#34;&gt;https://arxiv.org/pdf/2501.18837&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/constitutional-classifiers.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;alignment-faking-in-large-language-models&#34;&gt;Alignment Faking in Large Language Models&lt;/h2&gt;
&lt;p&gt;Anthropic (Dec 2024) &lt;a href=&#34;https://arxiv.org/pdf/2412.14093&#34;&gt;https://arxiv.org/pdf/2412.14093&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/alignment-faking.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;constitutional-ai-harmlessness-from-ai-feedback&#34;&gt;Constitutional AI: Harmlessness from AI Feedback&lt;/h2&gt;
&lt;p&gt;Anthropic (Dec 2022) &lt;a href=&#34;https://arxiv.org/pdf/2212.08073&#34;&gt;https://arxiv.org/pdf/2212.08073&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/constitutional-ai.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;pre-training&#34;&gt;Pre-training&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model&#34;&gt;DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model&lt;/h2&gt;
&lt;p&gt;DeepSeek (June 2024) &lt;a href=&#34;https://arxiv.org/pdf/2405.04434&#34;&gt;https://arxiv.org/pdf/2405.04434&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/deepseek-v2.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning&#34;&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning&lt;/h2&gt;
&lt;p&gt;DeepSeek (Jan 2025) &lt;a href=&#34;https://arxiv.org/pdf/2501.12948&#34;&gt;https://arxiv.org/pdf/2501.12948&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/deepseek-r1.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models&#34;&gt;DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models&lt;/h2&gt;
&lt;p&gt;DeepSeek (Apr 2024) &lt;a href=&#34;https://arxiv.org/pdf/2401.06066&#34;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/grpo.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Modern LLM Architectures with DeepSeek-V3</title>
      <link>http://localhost:1313/posts/gpt2-to-deepseekv3/</link>
      <pubDate>Sat, 14 Dec 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/gpt2-to-deepseekv3/</guid>
      <description>&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-architecture&#34;&gt;Model Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#inference&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;DeepSeek has quickly become a household name after their release of DeepSeek-R1 model which caused dramatic sell off of NVIDIA stock, causing its value to drop by roughly 17% in one trading session, erasing $593 billion in market value, a record one-day loss for any company on Wall Street (&lt;a href=&#34;https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/&#34;&gt;Reuters&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The intended audience of this post is someone who has a solid understanding of Deep Learning and GPT2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Alignment</title>
      <link>http://localhost:1313/posts/alignment/</link>
      <pubDate>Thu, 15 Feb 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/alignment/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h2 id=&#34;capabilities-vs-alignment&#34;&gt;Capabilities vs Alignment&lt;/h2&gt;
&lt;p&gt;The field of AI safety, there is an important distinction between &lt;strong&gt;capabilities evaluations&lt;/strong&gt; and &lt;strong&gt;alignment evaluations&lt;/strong&gt;. &lt;strong&gt;Capabilities evaluations&lt;/strong&gt; measures the the capacity  (i.e. what the model &amp;ldquo;can&amp;rdquo; do), such as its proficiency at logical reasoning, coding, or writing. &lt;strong&gt;Alignment evaluations&lt;/strong&gt; measures the tendency for models to exhibit certain behaviors (i.e. what the model &amp;ldquo;wants&amp;rdquo; to do), such as being helpful, honest, and harmless, &lt;a href=&#34;https://en.wikipedia.org/wiki/Sycophancy&#34;&gt;sycophantic&lt;/a&gt;, or deceptive.&lt;/p&gt;
&lt;p&gt;We can conceptualize different combinations of capabilities and alignment:&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepSeek-VL2</title>
      <link>http://localhost:1313/posts/deepseek-vl2/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/deepseek-vl2/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;ref/DeepSeek-VLM2.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Batch size&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Original text sequence length&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&#39;&lt;/code&gt;: Text sequence length + image tokens&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_n_images&lt;/code&gt;: Maximum number of images&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H, W&lt;/code&gt;: Original image height/width&lt;/li&gt;
&lt;li&gt;&lt;code&gt;h, w&lt;/code&gt;: Cropped image height/width&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_patches&lt;/code&gt;: Number of patches (Vision Encoder)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;embed_dim&lt;/code&gt;: Vision Encoder embedding dimension&lt;/li&gt;
&lt;li&gt;&lt;code&gt;D&lt;/code&gt;: Language model embedding dimension&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_tiles&lt;/code&gt;: Total number of image tiles&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prefix_tokens&lt;/code&gt;: Number of class tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vlm-architecture&#34;&gt;VLM Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;ref/DeepSeek-VLM-arch2.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s break down the full autoregressive workflow of DeepSeek-VL2, step-by-step, in words. This will cover both the initial processing of the prompt (which can be optimized with incremental prefilling) and the subsequent token-by-token generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Post</title>
      <link>http://localhost:1313/posts/my-first-post/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/my-first-post/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi there! My name is Michael Liu.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Agent Capabilities through the GAIA Benchmark</title>
      <link>http://localhost:1313/posts/agents/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/agents/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h2 id=&#34;gaia-benchmark-quantifying-real-world-agent-progress&#34;&gt;GAIA Benchmark: Quantifying Real-World Agent Progress&lt;/h2&gt;
&lt;p&gt;Evaluating AI agents necessitates benchmarks that transcend academic exercises and accurately reflect practical, real-world capabilities. While datasets like &lt;strong&gt;MMLU&lt;/strong&gt; assess knowledge domains, they do not fully capture the essential skills for effective agents in complex, everyday scenarios. The &lt;strong&gt;GAIA&lt;/strong&gt; (\textbf{G}eneral \textbf{AI} \textbf{A}ssistants) benchmark \citep{mialon2023gaia} provides a more pertinent evaluation: it challenges agents with tasks demanding &lt;strong&gt;reasoning&lt;/strong&gt;, &lt;strong&gt;tool utilization&lt;/strong&gt;, and &lt;strong&gt;multi-modal comprehension&lt;/strong&gt; within open-ended, real-world contexts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Hi there! I&amp;rsquo;m Michael Liu, a software engineer passionate about AI development and safety. I combine practical engineering experience with a deep interest in advancing AI technology in reliable and beneficial ways.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m currently seeking roles in AI development. You can view my &lt;a href=&#34;http://localhost:1313/Michael_Liu_Resume_2025-03-05.pdf&#34; target=&#34;_blank&#34;&gt;resume here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;professional-background&#34;&gt;Professional Background&lt;/h2&gt;
&lt;p&gt;I most recently served as a Software Development Engineer II at Amazon Web Services (AWS), where I was a key member of the Data Transfer Metering team. Our system processed 140 PB of data and $11 million in revenue daily, serving as a critical component of AWS&amp;rsquo;s infrastructure. During my tenure, I:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Resources</title>
      <link>http://localhost:1313/learning-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/learning-resources/</guid>
      <description>&lt;h2 id=&#34;timeless-essaysvideos&#34;&gt;Timeless Essays/Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The Bitter Lesson - &lt;a href=&#34;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&#34;&gt;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;most important century&amp;rdquo; blog post series - &lt;a href=&#34;https://www.cold-takes.com/most-important-century&#34;&gt;https://www.cold-takes.com/most-important-century&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Situational Awareness - &lt;a href=&#34;https://situational-awareness.ai/&#34;&gt;https://situational-awareness.ai/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Machines of Loving Grace - &lt;a href=&#34;https://darioamodei.com/machines-of-loving-grace&#34;&gt;https://darioamodei.com/machines-of-loving-grace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How Far Are We From An AI Einstein? - Adam Brown - &lt;a href=&#34;https://www.youtube.com/watch?v=LjY0i2B-Avc&#34;&gt;https://www.youtube.com/watch?v=LjY0i2B-Avc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stanford CS25: V4 I Hyung Won Chung of OpenAI (2:05 - 15:18) - &lt;a href=&#34;https://youtu.be/orDKvo8h71o?si=oFd2l7YQzOoGat1q&#34;&gt;https://youtu.be/orDKvo8h71o?si=oFd2l7YQzOoGat1q&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AlphaGo Documentary - &lt;a href=&#34;https://youtu.be/WXuK6gekU1Y?si=uuPxNmTrpUNwzPA5&#34;&gt;https://youtu.be/WXuK6gekU1Y?si=uuPxNmTrpUNwzPA5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrew Ng&amp;rsquo;s Career Advice / Reading Research Papers &lt;a href=&#34;https://youtu.be/733m6qBH-jI?si=OLaGzeqvuObpjl9H&#34;&gt;https://youtu.be/733m6qBH-jI?si=OLaGzeqvuObpjl9H&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;youtube-channelspodcasts&#34;&gt;Youtube Channels/Podcasts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dwarkesh Patel - &lt;a href=&#34;https://www.youtube.com/c/DwarkeshPatel&#34;&gt;https://www.youtube.com/c/DwarkeshPatel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AI Explained - &lt;a href=&#34;https://www.youtube.com/@aiexplained-official&#34;&gt;https://www.youtube.com/@aiexplained-official&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Latent Space - &lt;a href=&#34;https://www.youtube.com/@LatentSpacePod&#34;&gt;https://www.youtube.com/@LatentSpacePod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;80 000 hours - &lt;a href=&#34;https://www.youtube.com/@eightythousandhours&#34;&gt;https://www.youtube.com/@eightythousandhours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cognitive Revolution - &lt;a href=&#34;https://www.youtube.com/@CognitiveRevolutionPodcast&#34;&gt;https://www.youtube.com/@CognitiveRevolutionPodcast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Neel Nanda - &lt;a href=&#34;https://www.youtube.com/@neelnanda2469&#34;&gt;https://www.youtube.com/@neelnanda2469&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;courses&#34;&gt;Courses&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alignment Research Engineer Accelerator (ARENA) - &lt;a href=&#34;https://github.com/callummcdougall/ARENA_3.0&#34;&gt;https://github.com/callummcdougall/ARENA_3.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hugging Face - &lt;a href=&#34;https://huggingface.co/courses&#34;&gt;https://huggingface.co/courses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced Large Language Model Agents: Berkley MOOC - &lt;a href=&#34;https://llmagents-learning.org/sp25&#34;&gt;https://llmagents-learning.org/sp25&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrej Karpathy&amp;rsquo;s Zero to Hero Series - &lt;a href=&#34;https://karpathy.ai/zero-to-hero.html&#34;&gt;https://karpathy.ai/zero-to-hero.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From Deep Learning Foundations to Stable Diffusion - &lt;a href=&#34;https://course.fast.ai/Lessons/part2.html&#34;&gt;https://course.fast.ai/Lessons/part2.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DeepLearning.AI specializations (short courses are skippable imo) - &lt;a href=&#34;https://www.deeplearning.ai/&#34;&gt;https://www.deeplearning.ai/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blogs&#34;&gt;Blogs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GOATs
&lt;ul&gt;
&lt;li&gt;Gwern - &lt;a href=&#34;https://www.gwern.net/&#34;&gt;https://www.gwern.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lillian Weng&amp;rsquo;s Lil&amp;rsquo; Log - &lt;a href=&#34;https://lilianweng.github.io/&#34;&gt;https://lilianweng.github.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Alignment and Interpretability
&lt;ul&gt;
&lt;li&gt;Anthropic&amp;rsquo;s Alignment Science Blog - &lt;a href=&#34;https://alignment.anthropic.com/&#34;&gt;https://alignment.anthropic.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Anthropic&amp;rsquo;s Transformer Circuits Thread - &lt;a href=&#34;https://transformer-circuits.pub/&#34;&gt;https://transformer-circuits.pub/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LessWrong - &lt;a href=&#34;https://www.lesswrong.com/&#34;&gt;https://www.lesswrong.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning
&lt;ul&gt;
&lt;li&gt;RLHF Book - &lt;a href=&#34;https://rlhfbook.com/&#34;&gt;https://rlhfbook.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Industry Trends
&lt;ul&gt;
&lt;li&gt;Epoch AI - &lt;a href=&#34;https://epoch.ai/blog&#34;&gt;https://epoch.ai/blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SemiAnalysis - &lt;a href=&#34;https://www.semianalysis.com/&#34;&gt;https://www.semianalysis.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Agents
&lt;ul&gt;
&lt;li&gt;Anthropic: Building effective agents - &lt;a href=&#34;https://www.anthropic.com/research/building-effective-agents&#34;&gt;https://www.anthropic.com/research/building-effective-agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Google: Agents Whitepaper - &lt;a href=&#34;https://www.kaggle.com/whitepaper-agents&#34;&gt;https://www.kaggle.com/whitepaper-agents&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LLM Training
&lt;ul&gt;
&lt;li&gt;FineWeb - &lt;a href=&#34;https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&#34;&gt;https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to Scale Your Model: A Systems View of LLMs on TPUs - &lt;a href=&#34;https://jax-ml.github.io/scaling-book/&#34;&gt;https://jax-ml.github.io/scaling-book/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Ultra-Scale Playbook: Training LLMs on GPU Clusters - &lt;a href=&#34;https://huggingface.co/spaces/nanotron/ultrascale-playbook&#34;&gt;https://huggingface.co/spaces/nanotron/ultrascale-playbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Distributed Training] Picotron tutorial - &lt;a href=&#34;https://www.youtube.com/watch?v=u2VSwDDpaBM&amp;amp;list=PL-_armZiJvAnhcRr6yTJ0__f3Oi-LLi9S&#34;&gt;https://www.youtube.com/watch?v=u2VSwDDpaBM&amp;amp;list=PL-_armZiJvAnhcRr6yTJ0__f3Oi-LLi9S&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;github-repos&#34;&gt;Github Repos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;System Prompts
&lt;ul&gt;
&lt;li&gt;Leaked System Prompts - &lt;a href=&#34;https://github.com/jujumilk3/leaked-system-prompts&#34;&gt;https://github.com/jujumilk3/leaked-system-prompts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LLM Inference
&lt;ul&gt;
&lt;li&gt;EAGLE - &lt;a href=&#34;https://github.com/SafeAILab/EAGLE&#34;&gt;https://github.com/SafeAILab/EAGLE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SGLang - &lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;https://github.com/sgl-project/sglang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;vLLM - &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;https://github.com/vllm-project/vllm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TensorRT - &lt;a href=&#34;https://github.com/NVIDIA/TensorRT&#34;&gt;https://github.com/NVIDIA/TensorRT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning
&lt;ul&gt;
&lt;li&gt;verl - &lt;a href=&#34;https://github.com/volcengine/verl&#34;&gt;https://github.com/volcengine/verl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;trl - &lt;a href=&#34;https://github.com/huggingface/trl&#34;&gt;https://github.com/huggingface/trl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Search-R1 - &lt;a href=&#34;https://github.com/PeterGriffinJin/Search-R1&#34;&gt;https://github.com/PeterGriffinJin/Search-R1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Agents
&lt;ul&gt;
&lt;li&gt;smolagents - &lt;a href=&#34;https://github.com/huggingface/smolagents&#34;&gt;https://github.com/huggingface/smolagents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenHands (formerly OpenDevin) - &lt;a href=&#34;https://github.com/All-Hands-AI/OpenHands&#34;&gt;https://github.com/All-Hands-AI/OpenHands&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;textbooks&#34;&gt;Textbooks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reinforcement Learning by Richard S. Sutton and Andrew G. Barto - &lt;a href=&#34;https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf&#34;&gt;https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generative AI System Design Interview - &lt;a href=&#34;https://www.amazon.com/Generative-AI-System-Design-Interview/dp/1736049143&#34;&gt;https://www.amazon.com/Generative-AI-System-Design-Interview/dp/1736049143&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;newsletters&#34;&gt;Newsletters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI News - &lt;a href=&#34;https://buttondown.com/ainews/&#34;&gt;https://buttondown.com/ainews/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Latent Space - &lt;a href=&#34;https://www.latent.space/&#34;&gt;https://www.latent.space/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;China Talk - &lt;a href=&#34;https://www.chinatalk.media/&#34;&gt;https://www.chinatalk.media/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Import AI by Jack Clark - &lt;a href=&#34;https://importai.substack.com/&#34;&gt;https://importai.substack.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rohan&amp;rsquo;s Bytes - &lt;a href=&#34;https://rohanpaul.substack.com/&#34;&gt;https://rohanpaul.substack.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cursor - &lt;a href=&#34;https://www.cursor.com/&#34;&gt;https://www.cursor.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;alphaXiv - &lt;a href=&#34;https://www.alphaxiv.org/explore&#34;&gt;https://www.alphaxiv.org/explore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gitingest - &lt;a href=&#34;https://gitingest.com/&#34;&gt;https://gitingest.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;leetcode&#34;&gt;LeetCode&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NeetCode - &lt;a href=&#34;https://neetcode.io/&#34;&gt;https://neetcode.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-this-page&#34;&gt;What is this page?&lt;/h2&gt;
&lt;p&gt;This is my personal collection of AI learning resources that I&amp;rsquo;ve found valuable in my journey. While it primarily serves as my digital garden of knowledge links (which I keep permanently bookmarked for easy reference), I&amp;rsquo;m sharing it publicly for two important reasons:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Projects</title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description>&lt;h2 id=&#34;gpt-2-transformer-implementation-and-mechanistic-interpretability-experimentation&#34;&gt;GPT-2 Transformer Implementation and Mechanistic Interpretability Experimentation&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;GPT-2 Transformer&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/assets/images/gpt2-transformer-image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;A comprehensive implementation and exploration of transformer-based language models, focusing on GPT-2 architecture and mechanistic interpretability. This project features three main components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a production-ready lightweight implementation with efficient training pipelines based on Andrej Karpathy&amp;rsquo;s &lt;a href=&#34;https://github.com/karpathy/nanoGPT&#34;&gt;nanoGPT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a clean, educational GPT-2 implementation from scratch with detailed documentation and intuition (includes sampling techniques with temperature, top-k, top-p, beam search and KV caching)&lt;/li&gt;
&lt;li&gt;advanced mechanistic interpretability tools for analyzing model internals including attention patterns, induction heads, feature representations, circuit behavior, and toy models of superposition&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Built with PyTorch, &lt;a href=&#34;https://github.com/TransformerLensOrg/TransformerLens&#34;&gt;TransformerLens&lt;/a&gt;, and integrated with Weights &amp;amp; Biases for experiment tracking.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
