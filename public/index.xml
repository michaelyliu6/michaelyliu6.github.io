<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ML&#39;s Blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on ML&#39;s Blog</description>
    <generator>Hugo -- 0.140.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 14 Dec 2024 07:07:07 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ML Papers</title>
      <link>http://localhost:1313/posts/ml-papers/</link>
      <pubDate>Sat, 14 Dec 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/ml-papers/</guid>
      <description>&lt;h1 id=&#34;ai-alignment&#34;&gt;AI Alignment&lt;/h1&gt;
&lt;h2 id=&#34;constitutional-classifiers-defending-against-universal-jailbreaks-across-thousands-of-hours-of-red-teaming&#34;&gt;Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming&lt;/h2&gt;
&lt;p&gt;Anthropic (Jan 2025) &lt;a href=&#34;https://arxiv.org/pdf/2501.18837&#34;&gt;https://arxiv.org/pdf/2501.18837&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/constitutional-classifiers.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;alignment-faking-in-large-language-models&#34;&gt;Alignment Faking in Large Language Models&lt;/h2&gt;
&lt;p&gt;Anthropic (Dec 2024) &lt;a href=&#34;https://arxiv.org/pdf/2412.14093&#34;&gt;https://arxiv.org/pdf/2412.14093&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/alignment-faking.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;constitutional-ai-harmlessness-from-ai-feedback&#34;&gt;Constitutional AI: Harmlessness from AI Feedback&lt;/h2&gt;
&lt;p&gt;Anthropic (Dec 2022) &lt;a href=&#34;https://arxiv.org/pdf/2212.08073&#34;&gt;https://arxiv.org/pdf/2212.08073&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/constitutional-ai.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;pre-training&#34;&gt;Pre-training&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model&#34;&gt;DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model&lt;/h2&gt;
&lt;p&gt;DeepSeek (June 2024) &lt;a href=&#34;https://arxiv.org/pdf/2405.04434&#34;&gt;https://arxiv.org/pdf/2405.04434&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/deepseek-v2.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning&#34;&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning&lt;/h2&gt;
&lt;p&gt;DeepSeek (Jan 2025) &lt;a href=&#34;https://arxiv.org/pdf/2501.12948&#34;&gt;https://arxiv.org/pdf/2501.12948&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/deepseek-r1.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models&#34;&gt;DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models&lt;/h2&gt;
&lt;p&gt;DeepSeek (Apr 2024) &lt;a href=&#34;https://arxiv.org/pdf/2401.06066&#34;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/ml-papers/grpo.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Toy Diffusion Model</title>
      <link>http://localhost:1313/posts/part1_toy_model/</link>
      <pubDate>Sat, 14 Dec 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/part1_toy_model/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;img src=&#34;http://localhost:1313/assets/images/references/paper_background.png&#34; alt=&#34;Paper Background&#34;&gt;
&lt;figcaption&gt;&lt;code&gt;Section 2: Background&lt;/code&gt; in &lt;a href=&#34;https://arxiv.org/pdf/2006.11239#page=2&#34;&gt;Denoising Diffusion Probabilistic Models&lt;/a&gt;&lt;/figcaption&gt;
&lt;h3 id=&#34;equation-1-reverse-process&#34;&gt;Equation 1: Reverse Process&lt;/h3&gt;
&lt;p&gt;$p$ is a &lt;strong&gt;probability density function&lt;/strong&gt; that represents the &lt;strong&gt;reverse&lt;/strong&gt; process, the process of adding noise.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with the notation $p(x_T) = N(x_T; 0, I)$. $N$ is a normal distribution. $0$ is the mean (centered at zero). $I$ is the identity matrix representing the covariance (meaning that elements are independent with unit variance). It describes the distribution of completely random noise, which is the starting point $x_T$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Modern LLM Architectures with DeepSeek-V3</title>
      <link>http://localhost:1313/posts/gpt2-to-deepseekv3/</link>
      <pubDate>Sat, 14 Dec 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/gpt2-to-deepseekv3/</guid>
      <description>&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-architecture&#34;&gt;Model Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#inference&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;DeepSeek has quickly become a household name after their release of DeepSeek-R1 model which caused dramatic sell off of NVIDIA stock, causing its value to drop by roughly 17% in one trading session, erasing $593 billion in market value, a record one-day loss for any company on Wall Street (&lt;a href=&#34;https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/&#34;&gt;Reuters&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The intended audience of this post is someone who has a solid understanding of Deep Learning and GPT2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Sat, 17 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Hi there! I&amp;rsquo;m Michael Liu, a software engineer passionate about AI development and safety. I combine practical engineering experience with a deep interest in advancing AI technology in reliable and beneficial ways.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m currently seeking roles in AI development.&lt;/p&gt;
&lt;h2 id=&#34;professional-background&#34;&gt;Professional Background&lt;/h2&gt;
&lt;p&gt;I most recently served as a Software Development Engineer II at Amazon Web Services (AWS), where I was a key member of the Data transfer Metering team. Our system processed 140 PB of data and $11 million in revenue daily, serving as a critical component of AWS&amp;rsquo;s infrastructure. During my tenure, I:&lt;/p&gt;</description>
    </item>
    <item>
      <title>5 Predictions for AI in 2025</title>
      <link>http://localhost:1313/posts/predictions/</link>
      <pubDate>Thu, 15 Feb 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/predictions/</guid>
      <description>&lt;p&gt;2024 was a crazy year for AI, and it&amp;rsquo;s looking like 2025 is going to be even crazier. We have AI &amp;ldquo;expert&amp;rdquo;, Gary Marcus predicting that Deep Learning is hitting a wall and that the market is&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m a little late to the party as we are already a month into 2025, but none the less, here are my predictions for AI in 2025. To keep things spicy, I omitted the obvious predictions like &amp;ldquo;the cost of intelligence will go down&amp;rdquo; or &amp;ldquo;hallucinations won&amp;rsquo;t be solved&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Alignment</title>
      <link>http://localhost:1313/posts/alignment/</link>
      <pubDate>Thu, 15 Feb 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/alignment/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h2 id=&#34;capabilities-vs-alignment&#34;&gt;Capabilities vs Alignment&lt;/h2&gt;
&lt;p&gt;The field of AI safety, there is an important distinction between &lt;strong&gt;capabilities evaluations&lt;/strong&gt; and &lt;strong&gt;alignment evaluations&lt;/strong&gt;. &lt;strong&gt;Capabilities evaluations&lt;/strong&gt; measures the the capacity  (i.e. what the model &amp;ldquo;can&amp;rdquo; do), such as its proficiency at logical reasoning, coding, or writing. &lt;strong&gt;Alignment evaluations&lt;/strong&gt; measures the tendency for models to exhibit certain behaviors (i.e. what the model &amp;ldquo;wants&amp;rdquo; to do), such as being helpful, honest, and harmless, &lt;a href=&#34;https://en.wikipedia.org/wiki/Sycophancy&#34;&gt;sycophantic&lt;/a&gt;, or deceptive.&lt;/p&gt;
&lt;p&gt;We can conceptualize different combinations of capabilities and alignment:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training Language Models with Reinforcement Learning from Human Feedback</title>
      <link>http://localhost:1313/posts/rlhf/</link>
      <pubDate>Thu, 15 Feb 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/rlhf/</guid>
      <description>&lt;p&gt;Reinforcement Learning from Human Feedback (RLHF) is a technique used to fine-tune large language models (LLMs) to better align with human preferences. It involves training a reward model based on human feedback and then using reinforcement learning to optimize the LLM&amp;rsquo;s policy to maximize the reward.&lt;/p&gt;
&lt;p&gt;This process generally involves three key steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Supervised Fine-tuning (SFT):&lt;/strong&gt; An initial language model is fine-tuned on a dataset of high-quality demonstrations, where the model learns to imitate the provided examples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepSeek-VL2</title>
      <link>http://localhost:1313/posts/deepseek-vl2/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/deepseek-vl2/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;ref/DeepSeek-VLM2.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Batch size&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Original text sequence length&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&#39;&lt;/code&gt;: Text sequence length + image tokens&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_n_images&lt;/code&gt;: Maximum number of images&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H, W&lt;/code&gt;: Original image height/width&lt;/li&gt;
&lt;li&gt;&lt;code&gt;h, w&lt;/code&gt;: Cropped image height/width&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_patches&lt;/code&gt;: Number of patches (Vision Encoder)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;embed_dim&lt;/code&gt;: Vision Encoder embedding dimension&lt;/li&gt;
&lt;li&gt;&lt;code&gt;D&lt;/code&gt;: Language model embedding dimension&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_tiles&lt;/code&gt;: Total number of image tiles&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prefix_tokens&lt;/code&gt;: Number of class tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vlm-architecture&#34;&gt;VLM Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;ref/DeepSeek-VLM-arch2.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s break down the full autoregressive workflow of DeepSeek-VL2, step-by-step, in words. This will cover both the initial processing of the prompt (which can be optimized with incremental prefilling) and the subsequent token-by-token generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Post</title>
      <link>http://localhost:1313/posts/my-first-post/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/my-first-post/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi there! My name is Michael Liu.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Agent Capabilities through the GAIA Benchmark</title>
      <link>http://localhost:1313/posts/agents/</link>
      <pubDate>Sun, 14 Jan 2024 07:07:07 +0100</pubDate>
      <guid>http://localhost:1313/posts/agents/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h2 id=&#34;gaia-benchmark-quantifying-real-world-agent-progress&#34;&gt;GAIA Benchmark: Quantifying Real-World Agent Progress&lt;/h2&gt;
&lt;p&gt;Evaluating AI agents necessitates benchmarks that transcend academic exercises and accurately reflect practical, real-world capabilities. While datasets like &lt;strong&gt;MMLU&lt;/strong&gt; assess knowledge domains, they do not fully capture the essential skills for effective agents in complex, everyday scenarios. The &lt;strong&gt;GAIA&lt;/strong&gt; (\textbf{G}eneral \textbf{AI} \textbf{A}ssistants) benchmark \citep{mialon2023gaia} provides a more pertinent evaluation: it challenges agents with tasks demanding &lt;strong&gt;reasoning&lt;/strong&gt;, &lt;strong&gt;tool utilization&lt;/strong&gt;, and &lt;strong&gt;multi-modal comprehension&lt;/strong&gt; within open-ended, real-world contexts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Resources</title>
      <link>http://localhost:1313/learning-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/learning-resources/</guid>
      <description>&lt;h2 id=&#34;timeless-essaysvideos&#34;&gt;Timeless Essays/Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The Bitter Lesson - &lt;a href=&#34;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&#34;&gt;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;most important century&amp;rdquo; blog post series - &lt;a href=&#34;https://www.cold-takes.com/most-important-century&#34;&gt;https://www.cold-takes.com/most-important-century&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Situational Awareness - &lt;a href=&#34;https://situational-awareness.ai/&#34;&gt;https://situational-awareness.ai/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Machines of Loving Grace - &lt;a href=&#34;https://darioamodei.com/machines-of-loving-grace&#34;&gt;https://darioamodei.com/machines-of-loving-grace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stanford CS25: V4 I Hyung Won Chung of OpenAI (2:05 - 15:18) - &lt;a href=&#34;https://youtu.be/orDKvo8h71o?si=oFd2l7YQzOoGat1q&#34;&gt;https://youtu.be/orDKvo8h71o?si=oFd2l7YQzOoGat1q&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AlphaGo Documentary - &lt;a href=&#34;https://youtu.be/WXuK6gekU1Y?si=uuPxNmTrpUNwzPA5&#34;&gt;https://youtu.be/WXuK6gekU1Y?si=uuPxNmTrpUNwzPA5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrew Ng&amp;rsquo;s Career Advice / Reading Research Papers &lt;a href=&#34;https://youtu.be/733m6qBH-jI?si=OLaGzeqvuObpjl9H&#34;&gt;https://youtu.be/733m6qBH-jI?si=OLaGzeqvuObpjl9H&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;youtube-channelspodcasts&#34;&gt;Youtube Channels/Podcasts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dwarkesh Patel - &lt;a href=&#34;https://www.youtube.com/c/DwarkeshPatel&#34;&gt;https://www.youtube.com/c/DwarkeshPatel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AI Explained - &lt;a href=&#34;https://www.youtube.com/@aiexplained-official&#34;&gt;https://www.youtube.com/@aiexplained-official&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Latent Space - &lt;a href=&#34;https://www.youtube.com/@LatentSpacePod&#34;&gt;https://www.youtube.com/@LatentSpacePod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;80 000 hours - &lt;a href=&#34;https://www.youtube.com/@eightythousandhours&#34;&gt;https://www.youtube.com/@eightythousandhours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cognitive Revolution - &lt;a href=&#34;https://www.youtube.com/@CognitiveRevolutionPodcast&#34;&gt;https://www.youtube.com/@CognitiveRevolutionPodcast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Neel Nanda - &lt;a href=&#34;https://www.youtube.com/@neelnanda2469&#34;&gt;https://www.youtube.com/@neelnanda2469&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;courses&#34;&gt;Courses&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI Research Engineer Accelerator (ARENA) - &lt;a href=&#34;https://github.com/callummcdougall/ARENA_3.0&#34;&gt;https://github.com/callummcdougall/ARENA_3.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hugging Face - &lt;a href=&#34;https://huggingface.co/courses&#34;&gt;https://huggingface.co/courses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced Large Language Model Agents: Berkley MOOC - &lt;a href=&#34;https://llmagents-learning.org/sp25&#34;&gt;https://llmagents-learning.org/sp25&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrej Karpathy&amp;rsquo;s Zero to Hero Series - &lt;a href=&#34;https://karpathy.ai/zero-to-hero.html&#34;&gt;https://karpathy.ai/zero-to-hero.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From Deep Learning Foundations to Stable Diffusion - &lt;a href=&#34;https://course.fast.ai/Lessons/part2.html&#34;&gt;https://course.fast.ai/Lessons/part2.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DeepLearning.AI specializations (short courses are skippable imo) - &lt;a href=&#34;https://www.deeplearning.ai/&#34;&gt;https://www.deeplearning.ai/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blogs&#34;&gt;Blogs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GOATs
&lt;ul&gt;
&lt;li&gt;Gwern - &lt;a href=&#34;https://www.gwern.net/&#34;&gt;https://www.gwern.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lillian Weng&amp;rsquo;s Lil&amp;rsquo; Log - &lt;a href=&#34;https://lilianweng.github.io/&#34;&gt;https://lilianweng.github.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Alignment and Interpretability
&lt;ul&gt;
&lt;li&gt;Anthropic&amp;rsquo;s Alignment Science Blog - &lt;a href=&#34;https://alignment.anthropic.com/&#34;&gt;https://alignment.anthropic.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Anthropic&amp;rsquo;s Transformer Circuits Thread - &lt;a href=&#34;https://transformer-circuits.pub/&#34;&gt;https://transformer-circuits.pub/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LessWrong - &lt;a href=&#34;https://www.lesswrong.com/&#34;&gt;https://www.lesswrong.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning
&lt;ul&gt;
&lt;li&gt;RLHF Book - &lt;a href=&#34;https://rlhfbook.com/&#34;&gt;https://rlhfbook.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Industry Trends
&lt;ul&gt;
&lt;li&gt;Epoch AI - &lt;a href=&#34;https://epoch.ai/blog&#34;&gt;https://epoch.ai/blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SemiAnalysis - &lt;a href=&#34;https://www.semianalysis.com/&#34;&gt;https://www.semianalysis.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Agents
&lt;ul&gt;
&lt;li&gt;Anthropic: Building effective agents - &lt;a href=&#34;https://www.anthropic.com/research/building-effective-agents&#34;&gt;https://www.anthropic.com/research/building-effective-agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Google: Agents Whitepaper - &lt;a href=&#34;https://www.kaggle.com/whitepaper-agents&#34;&gt;https://www.kaggle.com/whitepaper-agents&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LLM Training
&lt;ul&gt;
&lt;li&gt;FineWeb - &lt;a href=&#34;https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&#34;&gt;https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to Scale Your Model: A Systems View of LLMs on TPUs - &lt;a href=&#34;https://jax-ml.github.io/scaling-book/&#34;&gt;https://jax-ml.github.io/scaling-book/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Ultra-Scale Playbook: Training LLMs on GPU Clusters - &lt;a href=&#34;https://huggingface.co/spaces/nanotron/ultrascale-playbook&#34;&gt;https://huggingface.co/spaces/nanotron/ultrascale-playbook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;github-repos&#34;&gt;Github Repos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LLM Inference
&lt;ul&gt;
&lt;li&gt;SGLang - &lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;https://github.com/sgl-project/sglang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;vLLM - &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;https://github.com/vllm-project/vllm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TensorRT - &lt;a href=&#34;https://github.com/NVIDIA/TensorRT&#34;&gt;https://github.com/NVIDIA/TensorRT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;System Prompts
&lt;ul&gt;
&lt;li&gt;Leaked System Prompts - &lt;a href=&#34;https://github.com/jujumilk3/leaked-system-prompts&#34;&gt;https://github.com/jujumilk3/leaked-system-prompts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Agents
&lt;ul&gt;
&lt;li&gt;smolagents - &lt;a href=&#34;https://github.com/huggingface/smolagents&#34;&gt;https://github.com/huggingface/smolagents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenHands (formerly OpenDevin) - &lt;a href=&#34;https://github.com/All-Hands-AI/OpenHands&#34;&gt;https://github.com/All-Hands-AI/OpenHands&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;textbooks&#34;&gt;Textbooks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reinforcement Learning by Richard S. Sutton and Andrew G. Barto - &lt;a href=&#34;https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf&#34;&gt;https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generative AI System Design Interview - &lt;a href=&#34;https://www.amazon.com/Generative-AI-System-Design-Interview/dp/1736049143&#34;&gt;https://www.amazon.com/Generative-AI-System-Design-Interview/dp/1736049143&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;newsletters&#34;&gt;Newsletters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI News - &lt;a href=&#34;https://buttondown.com/ainews/&#34;&gt;https://buttondown.com/ainews/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Latent Space - &lt;a href=&#34;https://www.latent.space/&#34;&gt;https://www.latent.space/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;China Talk - &lt;a href=&#34;https://www.chinatalk.media/&#34;&gt;https://www.chinatalk.media/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Import AI by Jack Clark - &lt;a href=&#34;https://importai.substack.com/&#34;&gt;https://importai.substack.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rohan&amp;rsquo;s Bytes - &lt;a href=&#34;https://rohanpaul.substack.com/&#34;&gt;https://rohanpaul.substack.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cursor - &lt;a href=&#34;https://www.cursor.com/&#34;&gt;https://www.cursor.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;alphaXiv - &lt;a href=&#34;https://www.alphaxiv.org/explore&#34;&gt;https://www.alphaxiv.org/explore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gitingest - &lt;a href=&#34;https://gitingest.com/&#34;&gt;https://gitingest.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;leetcode&#34;&gt;LeetCode&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NeetCode - &lt;a href=&#34;https://neetcode.io/&#34;&gt;https://neetcode.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-this-page&#34;&gt;What is this page?&lt;/h2&gt;
&lt;p&gt;This is my personal collection of AI learning resources that I&amp;rsquo;ve found valuable in my journey. While it primarily serves as my digital garden of knowledge links (which I keep permanently bookmarked for easy reference), I&amp;rsquo;m sharing it publicly for two important reasons:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Projects</title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description>&lt;h2 id=&#34;reinforcement-learning-implementations&#34;&gt;Reinforcement Learning Implementations&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;Reinforcement Learning&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/assets/images/rl-project-image.png&#34;&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Image Prompt&lt;/summary&gt;
&lt;i&gt;An anime-style scene depicting a group of cute robot characters in a world made of classic Atari game elements. In the foreground, an excited robot with glowing eyes and animated facial expressions has just successfully navigated through a Pac-Man-style maze filled with colorful dots and ghosts. The robot stands triumphantly at the maze exit, surrounded by sparkling reward particles and a floating &#39;10000 POINTS&#39; text in retro pixelated font. Behind it, the conquered maze shows its successful path highlighted in glowing light. From the successful robot&#39;s core, streams of colorful data and code are flowing back to three other robot characters waiting at different Atari-inspired challenges: one facing a wall of Space Invaders aliens, another preparing to bounce a Breakout ball with a paddle, and a third positioned before a Pong game setup. Each watching robot has holographic displays showing the successful algorithm and strategy being shared. All robots have distinct anime designs with expressive digital eyes, sleek bodies with retro gaming color schemes (reds, blues, yellows), and cute proportions. The background features a pixelated landscape with more Atari game elements including Adventure dragons and Asteroids space rocks. The scene is rendered in vibrant anime style with clean lines, digital effects, and the characteristic glow of arcade screens illuminating the robots&#39; metallic surfaces.&lt;/i&gt; - Generated by Flux 1.1 Pro
&lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;p&gt;A comprehensive collection of reinforcement learning algorithms from classical methods to modern deep RL approaches. This project includes implementations of multi-armed bandits, SARSA, Q-Learning, DQN, PPO, and RLHF with thorough documentation and experimental results. Built with Python, PyTorch, Gymnasium (OpenAI Gym), and WandB, showcasing expertise in algorithm implementation and data visualization.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
