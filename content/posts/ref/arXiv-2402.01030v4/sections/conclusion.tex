\section{Conclusions}
This work introduces \approach that employs executable Python code for the LLM agent's action, which is advantageous over using text or JSON action, especially in complex scenarios.
% 
We collect \approach-focused multi-turn interaction trajectories \dataname for instruction tuning, and train \modelname that is specially designed for seamless integration with Python and can execute sophisticated tasks (e.g., model training) leveraging existing Python packages and autonomously rectifying errors through self-debugging. 


\section*{Acknowledgement}
We thank the anonymous reviewers for their suggestions and comments.
% 
This research is based upon work supported by U.S. DARPA ECOLE Program No. HR00112390060 and U.S. DARPA ITM Program No. FA8650-23-C-7316 and KAIROS Program No. FA8750-19-2-1004. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.
% 
This work used the Delta system at the National Center for Supercomputing Applications through allocation CIS230256 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services \& Support (ACCESS, \citealt{boerner2023access}) program, which is supported by National Science Foundation grants \#2138259, \#2138286, \#2138307, \#2137603, and \#2138296.


\section*{Impact Statement}
This paper presents work whose goal is to advance LLM-based autonomous agents that can communicate with humans through natural language and assist human users by performing tasks in environments on behalf of humans.
% 
In this section, we discuss potential societal consequences, limitations, and future work related to our work and its goal.

\modelname is an initial prototype of an autonomous agent and still has several practical limitations. For example, it may suffer from hallucination commonly seen in LLMs (e.g., imagine the content of a variable without actually printing it out), suggesting the need for subsequent alignment \citep{ouyang2022training} for further improvements.

Despite being a prototype, \modelname has already demonstrated limited self-improving capability (e.g., self-debug error messages to improve its action) and the ability to interact with environments.
% 
Future work may build upon \modelname to develop better agents by having them perform extensive interactions within a given environment and iteratively bootstrap their self-improving capability to learn to improve from past mistakes.
% 
More powerful agents, as results of such algorithms, are potentially beneficial for solving a wide range of real-world problems  (e.g., theorem proving, drug discovery).
% 
As extensively discussed in \cite{eloundou2023gpts}, a fully autonomous agent may transform the current landscape of the labor market and impact the jobs of existing workers.

% 
Furthermore, since \approach directly grants access for the agent to freely execute code in a sandbox environment, in the worst scenario (e.g., in Sci-Fi movies), such an agent may potentially break free of the sandbox restriction and cause harm to the world through cyber-attack, highlighting the need for future work to design better safety mechanism to safeguard autonomous agents \citep{tang2024prioritizing}.
