\looseness=-1
\section{Related Work}
\subsection{Action Module in LLM Agents}
As detailed in \cite{wang2023survey}, LLM-based autonomous agents are typically structured around four components: customized profiles~\citep{park2023generative, qian2023communicative}, long-term memory capabilities~\citep{zhu2023ghost, fischer2023reflective}, reasoning and planning algorithms~\citep{wei2022chain, chen2023measuring}, and, most crucially, action modules. 
% 
The action modules are key to facilitating LLM agents to effectively interact with external entities, including humans~\citep{lee2022coauthor} and tools~\citep{qin2023tool} in the environment~\citep{wang2023mint,yang2024intercode}. 
% 
In this study, we address the critical problem of standardizing the action space for LLM agents. 
% 
We further discuss the difference between \approach and the line of work that uses code generation for problem-solving in \sref{sec:prior_code_action_work}.
%
We notice a concurrent study TaskWeaver~\citep{qiao2023taskweaver} similarly endorses the use of code. We discuss the principal distinctions in \sref{sec:taskweaver}.

\subsection{Improving LLM Agents}

Two primary methods for enhancing LLM agents are prompt engineering and instruction tuning, as surveyed by \cite{wang2023survey}.
% 
For \textit{prompt engineering}~\citep{liu2023pre}, numerous strategies have been introduced to improve the chain-of-thought reasoning~\citep{wei2022chain}, including self-consistency-based reasoning~\citep{wang2022self, chen2023measuring} and tree-based approaches~\citep{yao2023tree}. 
% 
Moreover, LLMs can be strategically prompted to reflect on previous plans~\citep{yao2023retroformer, wang2023describe, zhang2023prefer}, enabling them to refine initial actions through trial and error.
% 
Contrast to prompt engineering, \textit{instruction tuning} intrinsically enhances LLMs~\citep{chung2022scaling}, particularly in their agent capabilities~\citep{zeng2023agenttuning, chen2023fireact}. 
% 
For effective training, human annotators can curate expert demonstrations for specific agent tasks, such as web browsing \citep{yao2022webshop, nakano2021webgpt}. 
% 
% Additionally, advanced LLMs like GPT-4~\citep{openai2023gpt4} can be utilized to minimize human efforts. 
% 
To minimize human annotation efforts, prior work creates synthetic datasets using stronger LLMs to distill agent capabilities into local models, focusing on tool usage~\citep{Qin2023ToolLLMFL}, interaction~\citep{chen2023dress}, and social skills~\citep{liu2023training}.
% 
\dataname aligns with the latter approach and creates datasets using stronger LLMs.
% due to limited resources for annotation. 