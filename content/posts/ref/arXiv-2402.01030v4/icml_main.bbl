\begin{thebibliography}{75}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2022)Ahn, Brohan, Brown, Chebotar, Cortes, David, Finn, Fu, Gopalakrishnan, Hausman, Herzog, Ho, Hsu, Ibarz, Ichter, Irpan, Jang, Ruano, Jeffrey, Jesmonth, Joshi, Julian, Kalashnikov, Kuang, Lee, Levine, Lu, Luu, Parada, Pastor, Quiambao, Rao, Rettinghouse, Reyes, Sermanet, Sievers, Tan, Toshev, Vanhoucke, Xia, Xiao, Xu, Xu, Yan, and Zeng]{saycan2022arxiv}
Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Ho, D., Hsu, J., Ibarz, J., Ichter, B., Irpan, A., Jang, E., Ruano, R.~J., Jeffrey, K., Jesmonth, S., Joshi, N., Julian, R., Kalashnikov, D., Kuang, Y., Lee, K.-H., Levine, S., Lu, Y., Luu, L., Parada, C., Pastor, P., Quiambao, J., Rao, K., Rettinghouse, J., Reyes, D., Sermanet, P., Sievers, N., Tan, C., Toshev, A., Vanhoucke, V., Xia, F., Xiao, T., Xu, P., Xu, S., Yan, M., and Zeng, A.
\newblock Do as i can and not as i say: Grounding language in robotic affordances.
\newblock In \emph{arXiv preprint arXiv:2204.01691}, 2022.

\bibitem[Anonymous(2023)]{sharegpt_dataset}
Anonymous.
\newblock Sharegpt dataset.
\newblock \url{https://hf.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/blob/main/ShareGPT_V3_unfiltered_cleaned_split_no_imsorry.json}, 2023.
\newblock A dataset containing multi-turn conversations between human and LLM assistant.

\bibitem[Boerner et~al.(2023)Boerner, Deems, Furlani, Knuth, and Towns]{boerner2023access}
Boerner, T.~J., Deems, S., Furlani, T.~R., Knuth, S.~L., and Towns, J.
\newblock Access: Advancing innovation: Nsf’s advanced cyberinfrastructure coordination ecosystem: Services \& support.
\newblock In \emph{Practice and Experience in Advanced Research Computing}, pp.\  173--176. 2023.

\bibitem[Bran et~al.(2023)Bran, Cox, White, and Schwaller]{bran2023chemcrow}
Bran, A.~M., Cox, S., White, A.~D., and Schwaller, P.
\newblock Chemcrow: Augmenting large-language models with chemistry tools.
\newblock \emph{arXiv preprint arXiv:2304.05376}, 2023.

\bibitem[Cano et~al.(2023)Cano, Pagliardini, Köpf, Matoba, Mohtashami, Wang, Fan, Marmet, Bayazit, Krawczuk, Chen, Salvi, Bosselut, and Jaggi]{epfmgtrn}
Cano, A.~H., Pagliardini, M., Köpf, A., Matoba, K., Mohtashami, A., Wang, X., Fan, O.~S., Marmet, A., Bayazit, D., Krawczuk, I., Chen, Z., Salvi, F., Bosselut, A., and Jaggi, M.
\newblock epfllm megatron-llm, 2023.
\newblock URL \url{https://github.com/epfLLM/Megatron-LLM}.

\bibitem[Chase(2022)]{Chase_LangChain_2022}
Chase, H.
\newblock {LangChain}, October 2022.
\newblock URL \url{https://github.com/langchain-ai/langchain}.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Shu, Shareghi, Collier, Narasimhan, and Yao]{chen2023fireact}
Chen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K., and Yao, S.
\newblock Fireact: Toward language agent fine-tuning.
\newblock \emph{arXiv preprint arXiv:2310.05915}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d.~O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Lin, Sch{\"a}rli, and Zhou]{chen2023teaching}
Chen, X., Lin, M., Sch{\"a}rli, N., and Zhou, D.
\newblock Teaching large language models to self-debug.
\newblock \emph{arXiv preprint arXiv:2304.05128}, 2023{\natexlab{b}}.

\bibitem[Chen et~al.(2023{\natexlab{c}})Chen, Sikka, Cogswell, Ji, and Divakaran]{chen2023dress}
Chen, Y., Sikka, K., Cogswell, M., Ji, H., and Divakaran, A.
\newblock Dress: Instructing large vision-language models to align and interact with humans via natural language feedback.
\newblock \emph{arXiv preprint arXiv:2311.10081}, 2023{\natexlab{c}}.

\bibitem[Chen et~al.(2023{\natexlab{d}})Chen, Sikka, Cogswell, Ji, and Divakaran]{chen2023measuring}
Chen, Y., Sikka, K., Cogswell, M., Ji, H., and Divakaran, A.
\newblock Measuring and improving chain-of-thought reasoning in vision-language models.
\newblock \emph{arXiv preprint arXiv:2309.04461}, 2023{\natexlab{d}}.

\bibitem[Chung et~al.(2022)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang, Dehghani, Brahma, et~al.]{chung2022scaling}
Chung, H.~W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et~al.
\newblock Scaling instruction-finetuned language models.
\newblock \emph{arXiv preprint arXiv:2210.11416}, 2022.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Eloundou et~al.(2023)Eloundou, Manning, Mishkin, and Rock]{eloundou2023gpts}
Eloundou, T., Manning, S., Mishkin, P., and Rock, D.
\newblock Gpts are gpts: An early look at the labor market impact potential of large language models.
\newblock \emph{arXiv preprint arXiv:2303.10130}, 2023.

\bibitem[Fischer(2023)]{fischer2023reflective}
Fischer, K.~A.
\newblock Reflective linguistic programming (rlp): A stepping stone in socially-aware agi (socialagi).
\newblock \emph{arXiv preprint arXiv:2305.12647}, 2023.

\bibitem[Gao et~al.(2023)Gao, Madaan, Zhou, Alon, Liu, Yang, Callan, and Neubig]{gao2023pal}
Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., and Neubig, G.
\newblock Pal: Program-aided language models.
\newblock In \emph{International Conference on Machine Learning}, pp.\  10764--10799. PMLR, 2023.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.
\newblock Measuring massive multitask language understanding.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Kadavath, Mazeika, Arora, Guo, Burns, Puranik, He, Song, et~al.]{hendrycks2021measuring}
Hendrycks, D., Basart, S., Kadavath, S., Mazeika, M., Arora, A., Guo, E., Burns, C., Puranik, S., He, H., Song, D., et~al.
\newblock Measuring coding challenge competence with apps.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycks2021math}
Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}, 2021{\natexlab{b}}.

\bibitem[Hong et~al.(2023)Hong, Zheng, Chen, Cheng, Wang, Zhang, Wang, Yau, Lin, Zhou, et~al.]{hong2023metagpt}
Hong, S., Zheng, X., Chen, J., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K.~S., Lin, Z., Zhou, L., et~al.
\newblock Metagpt: Meta programming for multi-agent collaborative framework.
\newblock \emph{arXiv preprint arXiv:2308.00352}, 2023.

\bibitem[Hong et~al.(2024)Hong, Lin, Liu, Liu, Wu, Li, Chen, Zhang, Wang, Zhang, Zhang, Yang, Zhuge, Guo, Zhou, Tao, Wang, Tang, Lu, Zheng, Liang, Fei, Cheng, Xu, and Wu]{hong2024data}
Hong, S., Lin, Y., Liu, B., Liu, B., Wu, B., Li, D., Chen, J., Zhang, J., Wang, J., Zhang, L., Zhang, L., Yang, M., Zhuge, M., Guo, T., Zhou, T., Tao, W., Wang, W., Tang, X., Lu, X., Zheng, X., Liang, X., Fei, Y., Cheng, Y., Xu, Z., and Wu, C.
\newblock Data interpreter: An llm agent for data science, 2024.

\bibitem[Huang et~al.(2023)Huang, Wang, Zhang, Li, Wu, and Fei-Fei]{huang2023voxposer}
Huang, W., Wang, C., Zhang, R., Li, Y., Wu, J., and Fei-Fei, L.
\newblock Voxposer: Composable 3d value maps for robotic manipulation with language models.
\newblock \emph{arXiv preprint arXiv:2307.05973}, 2023.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, Casas, Bressand, Lengyel, Lample, Saulnier, et~al.]{jiang2023mistral}
Jiang, A.~Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.~S., Casas, D. d.~l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et~al.
\newblock Mistral 7b.
\newblock \emph{arXiv preprint arXiv:2310.06825}, 2023.

\bibitem[Kim et~al.(2023)Kim, Baldi, and McAleer]{kim2023language}
Kim, G., Baldi, P., and McAleer, S.
\newblock Language models can solve computer tasks.
\newblock \emph{arXiv preprint arXiv:2303.17491}, 2023.

\bibitem[LDJnr(2023)]{capybara_dataset}
LDJnr.
\newblock Capybara dataset.
\newblock \url{https://hf.co/datasets/LDJnr/Verified-Camel}, \url{https://hf.co/datasets/LDJnr/Pure-Dove}, \url{https://hf.co/datasets/LDJnr/LessWrong-Amplify-Instruct}, 2023.
\newblock A dataset focusing on reasoning in multi-turn conversations.

\bibitem[Lee et~al.(2022)Lee, Liang, and Yang]{lee2022coauthor}
Lee, M., Liang, P., and Yang, Q.
\newblock Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities.
\newblock In \emph{Proceedings of the 2022 CHI conference on human factors in computing systems}, pp.\  1--19, 2022.

\bibitem[Li et~al.(2023)Li, Song, Yu, Yu, Li, Huang, and Li]{li2023apibank}
Li, M., Song, F., Yu, B., Yu, H., Li, Z., Huang, F., and Li, Y.
\newblock Api-bank: A benchmark for tool-augmented llms, 2023.

\bibitem[Lian et~al.(2023)Lian, Goodson, Pentland, Cook, Vong, and "Teknium"]{OpenOrca}
Lian, W., Goodson, B., Pentland, E., Cook, A., Vong, C., and "Teknium".
\newblock Openorca: An open dataset of gpt augmented flan reasoning traces.
\newblock \url{https://https://huggingface.co/Open-Orca/OpenOrca}, 2023.

\bibitem[Liang et~al.(2022)Liang, Huang, Xia, Xu, Hausman, Ichter, Florence, and Zeng]{codeaspolicies2022}
Liang, J., Huang, W., Xia, F., Xu, P., Hausman, K., Ichter, B., Florence, P., and Zeng, A.
\newblock Code as policies: Language model programs for embodied control.
\newblock In \emph{arXiv preprint arXiv:2209.07753}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Yuan, Fu, Jiang, Hayashi, and Neubig]{liu2023pre}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.
\newblock \emph{ACM Computing Surveys}, 55\penalty0 (9):\penalty0 1--35, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Yang, Jia, Zhang, Zhou, Dai, Yang, and Vosoughi]{liu2023training}
Liu, R., Yang, R., Jia, C., Zhang, G., Zhou, D., Dai, A.~M., Yang, D., and Vosoughi, S.
\newblock Training socially aligned language models in simulated human society.
\newblock \emph{arXiv preprint arXiv:2305.16960}, 2023{\natexlab{b}}.

\bibitem[Ma et~al.(2023)Ma, Liang, Wang, Huang, Bastani, Jayaraman, Zhu, Fan, and Anandkumar]{ma2023eureka}
Ma, Y.~J., Liang, W., Wang, G., Huang, D.-A., Bastani, O., Jayaraman, D., Zhu, Y., Fan, L., and Anandkumar, A.
\newblock Eureka: Human-level reward design via coding large language models.
\newblock \emph{arXiv preprint arXiv:2310.12931}, 2023.

\bibitem[Mialon et~al.(2023)Mialon, Dess{\`\i}, Lomeli, Nalmpantis, Pasunuru, Raileanu, Rozi{\`e}re, Schick, Dwivedi-Yu, Celikyilmaz, et~al.]{mialon2023augmented}
Mialon, G., Dess{\`\i}, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozi{\`e}re, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., et~al.
\newblock Augmented language models: a survey.
\newblock \emph{arXiv preprint arXiv:2302.07842}, 2023.

\bibitem[Nakano et~al.(2021)Nakano, Hilton, Balaji, Wu, Ouyang, Kim, Hesse, Jain, Kosaraju, Saunders, et~al.]{nakano2021webgpt}
Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et~al.
\newblock Webgpt: Browser-assisted question-answering with human feedback.
\newblock \emph{arXiv preprint arXiv:2112.09332}, 2021.

\bibitem[OpenChat(2023)]{sharegpt4_dataset}
OpenChat.
\newblock Sharegpt dataset.
\newblock \url{https://hf.co/datasets/openchat/openchat_sharegpt_v3/blob/main/sharegpt_gpt4.json}, 2023.
\newblock A dataset containing multi-turn conversations between human and LLM assistants. It is filtered to contain data only from GPT-4.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27730--27744, 2022.

\bibitem[Park et~al.(2023)Park, O'Brien, Cai, Morris, Liang, and Bernstein]{park2023generative}
Park, J.~S., O'Brien, J., Cai, C.~J., Morris, M.~R., Liang, P., and Bernstein, M.~S.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock In \emph{Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology}, pp.\  1--22, 2023.

\bibitem[Pasupat \& Liang(2015)Pasupat and Liang]{pasupat2015compositional}
Pasupat, P. and Liang, P.
\newblock Compositional semantic parsing on semi-structured tables.
\newblock In \emph{Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pp.\  1470--1480, 2015.

\bibitem[Patil et~al.(2023)Patil, Zhang, Wang, and Gonzalez]{Patil2023GorillaLL}
Patil, S.~G., Zhang, T., Wang, X., and Gonzalez, J.~E.
\newblock Gorilla: Large language model connected with massive apis.
\newblock \emph{ArXiv}, abs/2305.15334, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:258865184}.

\bibitem[Qian et~al.(2023)Qian, Cong, Yang, Chen, Su, Xu, Liu, and Sun]{qian2023communicative}
Qian, C., Cong, X., Yang, C., Chen, W., Su, Y., Xu, J., Liu, Z., and Sun, M.
\newblock Communicative agents for software development.
\newblock \emph{arXiv preprint arXiv:2307.07924}, 2023.

\bibitem[Qiao et~al.(2023)Qiao, Li, Zhang, He, Kang, Zhang, Yang, Dong, Zhang, Wang, et~al.]{qiao2023taskweaver}
Qiao, B., Li, L., Zhang, X., He, S., Kang, Y., Zhang, C., Yang, F., Dong, H., Zhang, J., Wang, L., et~al.
\newblock Taskweaver: A code-first agent framework.
\newblock \emph{arXiv preprint arXiv:2311.17541}, 2023.

\bibitem[Qin et~al.(2023{\natexlab{a}})Qin, Hu, Lin, Chen, Ding, Cui, Zeng, Huang, Xiao, Han, et~al.]{qin2023tool}
Qin, Y., Hu, S., Lin, Y., Chen, W., Ding, N., Cui, G., Zeng, Z., Huang, Y., Xiao, C., Han, C., et~al.
\newblock Tool learning with foundation models.
\newblock \emph{arXiv preprint arXiv:2304.08354}, 2023{\natexlab{a}}.

\bibitem[Qin et~al.(2023{\natexlab{b}})Qin, Liang, Ye, Zhu, Yan, Lu, Lin, Cong, Tang, Qian, Zhao, Tian, Xie, Zhou, Gerstein, Li, Liu, and Sun]{Qin2023ToolLLMFL}
Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y.-T., Lin, Y., Cong, X., Tang, X., Qian, B., Zhao, S., Tian, R., Xie, R., Zhou, J., Gerstein, M.~H., Li, D., Liu, Z., and Sun, M.
\newblock Toolllm: Facilitating large language models to master 16000+ real-world apis.
\newblock \emph{ArXiv}, abs/2307.16789, 2023{\natexlab{b}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:260334759}.

\bibitem[Schick et~al.(2023)Schick, Dwivedi-Yu, Dess{\`\i}, Raileanu, Lomeli, Zettlemoyer, Cancedda, and Scialom]{schick2023toolformer}
Schick, T., Dwivedi-Yu, J., Dess{\`\i}, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T.
\newblock Toolformer: Language models can teach themselves to use tools.
\newblock \emph{arXiv preprint arXiv:2302.04761}, 2023.

\bibitem[Shen et~al.(2023)Shen, Song, Tan, Li, Lu, and Zhuang]{shen2023hugginggpt}
Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y.
\newblock Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface.
\newblock \emph{arXiv preprint arXiv:2303.17580}, 2023.

\bibitem[Shridhar et~al.(2020)Shridhar, Yuan, Cote, Bisk, Trischler, and Hausknecht]{shridhar2020alfworld}
Shridhar, M., Yuan, X., Cote, M.-A., Bisk, Y., Trischler, A., and Hausknecht, M.
\newblock Alfworld: Aligning text and embodied environments for interactive learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Singh et~al.(2023)Singh, Blukis, Mousavian, Goyal, Xu, Tremblay, Fox, Thomason, and Garg]{progprompt}
Singh, I., Blukis, V., Mousavian, A., Goyal, A., Xu, D., Tremblay, J., Fox, D., Thomason, J., and Garg, A.
\newblock Progprompt: Generating situated robot task plans using large language models.
\newblock In \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, pp.\  11523--11530, 2023.
\newblock \doi{10.1109/ICRA48891.2023.10161317}.

\bibitem[Sur\'is et~al.(2023)Sur\'is, Menon, and Vondrick]{surismenon2023vipergpt}
Sur\'is, D., Menon, S., and Vondrick, C.
\newblock Vipergpt: Visual inference via python execution for reasoning.
\newblock \emph{Proceedings of IEEE International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Tang et~al.(2024)Tang, Jin, Zhu, Yuan, Zhang, Zhou, Qu, Zhao, Tang, Zhang, et~al.]{tang2024prioritizing}
Tang, X., Jin, Q., Zhu, K., Yuan, T., Zhang, Y., Zhou, W., Qu, M., Zhao, Y., Tang, J., Zhang, Z., et~al.
\newblock Prioritizing safeguarding over autonomy: Risks of llm agents for science.
\newblock \emph{arXiv preprint arXiv:2402.04247}, 2024.

\bibitem[{TIOBE Index}(2024)]{tiobe}
{TIOBE Index}.
\newblock Tiobe index.
\newblock \url{https://www.tiobe.com/tiobe-index/}, Accessed at Jan 23rd, 2024, 2024.
\newblock The TIOBE Programming Community index is an indicator of the popularity of programming languages. The index is updated once a month. The ratings are based on the number of skilled engineers world-wide, courses and third party vendors.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Xie, Jiang, Mandlekar, Xiao, Zhu, Fan, and Anandkumar]{wang2023voyager}
Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A.
\newblock Voyager: An open-ended embodied agent with large language models.
\newblock \emph{arXiv preprint arXiv:2305.16291}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Ma, Feng, Zhang, Yang, Zhang, Chen, Tang, Chen, Lin, et~al.]{wang2023survey}
Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et~al.
\newblock A survey on large language model based autonomous agents.
\newblock \emph{arXiv preprint arXiv:2308.11432}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Jansen, C{\^o}t{\'e}, and Ammanabrolu]{Wang2022ScienceWorldIY}
Wang, R., Jansen, P.~A., C{\^o}t{\'e}, M.-A., and Ammanabrolu, P.
\newblock Scienceworld: Is your agent smarter than a 5th grader?
\newblock In \emph{Conference on Empirical Methods in Natural Language Processing}, 2022{\natexlab{a}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:247451124}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou]{wang2022self}
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., and Zhou, D.
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock \emph{arXiv preprint arXiv:2203.11171}, 2022{\natexlab{b}}.

\bibitem[Wang et~al.(2023{\natexlab{c}})Wang, Li, and Ji]{wang-etal-2023-code4struct}
Wang, X., Li, S., and Ji, H.
\newblock {C}ode4{S}truct: Code generation for few-shot event structure prediction.
\newblock In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  3640--3663, Toronto, Canada, July 2023{\natexlab{c}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.202}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.202}.

\bibitem[Wang et~al.(2023{\natexlab{d}})Wang, Peng, Jabbarvand, and Ji]{Wang2023LeTI}
Wang, X., Peng, H., Jabbarvand, R., and Ji, H.
\newblock Leti: Learning to generate from textual interactions.
\newblock \emph{ArXiv}, abs/2305.10314, 2023{\natexlab{d}}.

\bibitem[Wang et~al.(2023{\natexlab{e}})Wang, Wang, Liu, Chen, Yuan, Peng, and Ji]{wang2023mint}
Wang, X., Wang, Z., Liu, J., Chen, Y., Yuan, L., Peng, H., and Ji, H.
\newblock Mint: Evaluating llms in multi-turn interaction with tools and language feedback.
\newblock \emph{arXiv preprint arXiv:2309.10691}, 2023{\natexlab{e}}.

\bibitem[Wang et~al.(2023{\natexlab{f}})Wang, Cai, Liu, Ma, and Liang]{wang2023describe}
Wang, Z., Cai, S., Liu, A., Ma, X., and Liang, Y.
\newblock Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.
\newblock \emph{arXiv preprint arXiv:2302.01560}, 2023{\natexlab{f}}.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Xia, Chi, Le, Zhou, et~al.]{wei2022chain}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.~V., Zhou, D., et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 24824--24837, 2022.

\bibitem[Xu et~al.(2023)Xu, Hong, Li, Hu, Chen, and Zhang]{xu2023tool}
Xu, Q., Hong, F., Li, B., Hu, C., Chen, Z., and Zhang, J.
\newblock On the tool manipulation capability of open-source large language models, 2023.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Prabhakar, Narasimhan, and Yao]{yang2024intercode}
Yang, J., Prabhakar, A., Narasimhan, K., and Yao, S.
\newblock Intercode: Standardizing and benchmarking interactive coding with execution feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Liu, Wu, Yang, Fung, Li, Huang, Cao, Wang, Wang, Ji, and Zhai]{yang2024llm}
Yang, K., Liu, J., Wu, J., Yang, C., Fung, Y.~R., Li, S., Huang, Z., Cao, X., Wang, X., Wang, Y., Ji, H., and Zhai, C.
\newblock If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents, 2024{\natexlab{b}}.

\bibitem[Yang et~al.(2018)Yang, Qi, Zhang, Bengio, Cohen, Salakhutdinov, and Manning]{yang2018hotpotqa}
Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W., Salakhutdinov, R., and Manning, C.~D.
\newblock Hotpotqa: A dataset for diverse, explainable multi-hop question answering.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing}, pp.\  2369--2380, 2018.

\bibitem[Yang et~al.(2024{\natexlab{c}})Yang, Liu, Liu, Liu, Xiong, Wang, Yang, Hu, Chen, Zhang, Luo, Guo, Li, and Liu]{yang2024unified}
Yang, Z., Liu, A., Liu, Z., Liu, K., Xiong, F., Wang, Y., Yang, Z., Hu, Q., Chen, X., Zhang, Z., Luo, F., Guo, Z., Li, P., and Liu, Y.
\newblock Towards unified alignment between agents, humans, and environment, 2024{\natexlab{c}}.

\bibitem[Yao et~al.(2022{\natexlab{a}})Yao, Chen, Yang, and Narasimhan]{yao2022webshop}
Yao, S., Chen, H., Yang, J., and Narasimhan, K.
\newblock Webshop: Towards scalable real-world web interaction with grounded language agents.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 20744--20757, 2022{\natexlab{a}}.

\bibitem[Yao et~al.(2022{\natexlab{b}})Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{yao2022react}
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K.~R., and Cao, Y.
\newblock React: Synergizing reasoning and acting in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022{\natexlab{b}}.

\bibitem[Yao et~al.(2023{\natexlab{a}})Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{yao2023tree}
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T.~L., Cao, Y., and Narasimhan, K.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock \emph{arXiv preprint arXiv:2305.10601}, 2023{\natexlab{a}}.

\bibitem[Yao et~al.(2023{\natexlab{b}})Yao, Heinecke, Niebles, Liu, Feng, Xue, Murthy, Chen, Zhang, Arpit, et~al.]{yao2023retroformer}
Yao, W., Heinecke, S., Niebles, J.~C., Liu, Z., Feng, Y., Xue, L., Murthy, R., Chen, Z., Zhang, J., Arpit, D., et~al.
\newblock Retroformer: Retrospective large language agents with policy gradient optimization.
\newblock \emph{arXiv preprint arXiv:2308.02151}, 2023{\natexlab{b}}.

\bibitem[Yuan et~al.(2023)Yuan, Chen, Wang, Fung, Peng, and Ji]{Yuan2023CRAFTCL}
Yuan, L., Chen, Y., Wang, X., Fung, Y.~R., Peng, H., and Ji, H.
\newblock Craft: Customizing llms by creating and retrieving from specialized toolsets.
\newblock \emph{ArXiv}, abs/2309.17428, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263310662}.

\bibitem[Zeng et~al.(2023)Zeng, Liu, Lu, Wang, Liu, Dong, and Tang]{zeng2023agenttuning}
Zeng, A., Liu, M., Lu, R., Wang, B., Liu, X., Dong, Y., and Tang, J.
\newblock Agenttuning: Enabling generalized agent abilities for llms, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Liu, Wang, Wang, Sun, Wang, and Cai]{zhang2023prefer}
Zhang, C., Liu, L., Wang, J., Wang, C., Sun, X., Wang, H., and Cai, M.
\newblock Prefer: Prompt ensemble learning via feedback-reflect-refine.
\newblock \emph{arXiv preprint arXiv:2308.12033}, 2023.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, et~al.]{zheng2023judging}
Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock \emph{arXiv preprint arXiv:2306.05685}, 2023.

\bibitem[Zheng et~al.(2024)Zheng, Zhang, Shen, Liu, Lin, Fu, Chen, and Yue]{opencodeinterpreter}
Zheng, T., Zhang, G., Shen, T., Liu, X., Lin, B.~Y., Fu, J., Chen, W., and Yue, X.
\newblock Opencodeinterpreter: Integrating code generation with execution and refinement.
\newblock \emph{https://arxiv.org/abs/2402.14658}, 2024.

\bibitem[Zhu et~al.(2023)Zhu, Chen, Tian, Tao, Su, Yang, Huang, Li, Lu, Wang, et~al.]{zhu2023ghost}
Zhu, X., Chen, Y., Tian, H., Tao, C., Su, W., Yang, C., Huang, G., Li, B., Lu, L., Wang, X., et~al.
\newblock Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory.
\newblock \emph{arXiv preprint arXiv:2305.17144}, 2023.

\end{thebibliography}
