@article{ma2023eureka,
  title={Eureka: Human-level reward design via coding large language models},
  author={Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2310.12931},
  year={2023}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}


@article{mialon2023augmented,
  title={Augmented language models: a survey},
  author={Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2302.07842},
  year={2023}
}

@article{bran2023chemcrow,
  title={ChemCrow: Augmenting large-language models with chemistry tools},
  author={Bran, Andres M and Cox, Sam and White, Andrew D and Schwaller, Philippe},
  journal={arXiv preprint arXiv:2304.05376},
  year={2023}
}

@article{qin2023tool,
  title={Tool learning with foundation models},
  author={Qin, Yujia and Hu, Shengding and Lin, Yankai and Chen, Weize and Ding, Ning and Cui, Ganqu and Zeng, Zheni and Huang, Yufei and Xiao, Chaojun and Han, Chi and others},
  journal={arXiv preprint arXiv:2304.08354},
  year={2023}
}

@article{Yuan2023CRAFTCL,
  title={CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets},
  author={Lifan Yuan and Yangyi Chen and Xingyao Wang and Yi Ren Fung and Hao Peng and Heng Ji},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.17428},
  url={https://api.semanticscholar.org/CorpusID:263310662}
}
@article{yao2023retroformer,
  title={Retroformer: Retrospective large language agents with policy gradient optimization},
  author={Yao, Weiran and Heinecke, Shelby and Niebles, Juan Carlos and Liu, Zhiwei and Feng, Yihao and Xue, Le and Murthy, Rithesh and Chen, Zeyuan and Zhang, Jianguo and Arpit, Devansh and others},
  journal={arXiv preprint arXiv:2308.02151},
  year={2023}
}
@article{qiao2023taskweaver,
  title={TaskWeaver: A Code-First Agent Framework},
  author={Qiao, Bo and Li, Liqun and Zhang, Xu and He, Shilin and Kang, Yu and Zhang, Chaoyun and Yang, Fangkai and Dong, Hang and Zhang, Jue and Wang, Lu and others},
  journal={arXiv preprint arXiv:2311.17541},
  year={2023}
}


@article{chen2023fireact,
  title={Fireact: Toward language agent fine-tuning},
  author={Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2310.05915},
  year={2023}
}
@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}
@article{liu2023training,
  title={Training Socially Aligned Language Models in Simulated Human Society},
  author={Liu, Ruibo and Yang, Ruixin and Jia, Chenyan and Zhang, Ge and Zhou, Denny and Dai, Andrew M and Yang, Diyi and Vosoughi, Soroush},
  journal={arXiv preprint arXiv:2305.16960},
  year={2023}
}


@article{chen2023dress,
  title={DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback},
  author={Chen, Yangyi and Sikka, Karan and Cogswell, Michael and Ji, Heng and Divakaran, Ajay},
  journal={arXiv preprint arXiv:2311.10081},
  year={2023}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}
@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}
@article{zhang2023prefer,
  title={Prefer: Prompt ensemble learning via feedback-reflect-refine},
  author={Zhang, Chenrui and Liu, Lin and Wang, Jinpeng and Wang, Chuyuan and Sun, Xiao and Wang, Hongyu and Cai, Mingchen},
  journal={arXiv preprint arXiv:2308.12033},
  year={2023}
}


@article{wang2023describe,
  title={Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents},
  author={Wang, Zihao and Cai, Shaofei and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
  journal={arXiv preprint arXiv:2302.01560},
  year={2023}
}


@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}
@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}
@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@misc{li2023apibank,
  title={API-Bank: A Benchmark for Tool-Augmented LLMs}, 
  author={Minghao Li and Feifan Song and Bowen Yu and Haiyang Yu and Zhoujun Li and Fei Huang and Yongbin Li},
  year={2023},
  eprint={2304.08244},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}


@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@inproceedings{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@software{Chase_LangChain_2022,
author = {Chase, Harrison},
month = oct,
title = {{LangChain}},
url = {https://github.com/langchain-ai/langchain},
year = {2022}
}

@inproceedings{codeaspolicies2022,
    title={Code as Policies: Language Model Programs for Embodied Control},
    author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},
    booktitle={arXiv preprint arXiv:2209.07753},
    year={2022}
}

@article{wang2023mint,
  title={Mint: Evaluating llms in multi-turn interaction with tools and language feedback},
  author={Wang, Xingyao and Wang, Zihan and Liu, Jiateng and Chen, Yangyi and Yuan, Lifan and Peng, Hao and Ji, Heng},
  journal={arXiv preprint arXiv:2309.10691},
  year={2023}
}

@article{shen2023hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2303.17580},
  year={2023}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}

@article{Wang2023LeTI,
  title={LeTI: Learning to Generate from Textual Interactions},
  author={Xingyao Wang and Hao Peng and Reyhaneh Jabbarvand and Heng Ji},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.10314},
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{Kocetkov2022TheStack,
  title={The Stack: 3 TB of permissively licensed source code},
  author={Kocetkov, Denis and Li, Raymond and Allal, Loubna Ben and Li, Jia and Mou, Chenghao and Ferrandis, Carlos Mu{\~n}oz and Jernite, Yacine and Mitchell, Margaret and Hughes, Sean and Wolf, Thomas and others},
  journal={arXiv preprint arXiv:2211.15533},
  year={2022}
}


@article{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@software{Significant_Gravitas_AutoGPT,
author = {{Significant Gravitas}},
license = {MIT},
title = {{AutoGPT}},
url = {https://github.com/Significant-Gravitas/AutoGPT},
year = {2024}
}

@article{Qin2023ToolLLMFL,
  title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs},
  author={Yujia Qin and Shi Liang and Yining Ye and Kunlun Zhu and Lan Yan and Ya-Ting Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Marc H. Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.16789},
  url={https://api.semanticscholar.org/CorpusID:260334759}
}

@article{Patil2023GorillaLL,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.15334},
  url={https://api.semanticscholar.org/CorpusID:258865184}
}

@article{Tang2023ToolAlpacaGT,
  title={ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases},
  author={Qiaoyu Tang and Ziliang Deng and Hongyu Lin and Xianpei Han and Qiao Liang and Le Sun},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.05301},
  url={https://api.semanticscholar.org/CorpusID:259108190}
}

@misc{xu2023tool,
      title={On the Tool Manipulation Capability of Open-source Large Language Models}, 
      author={Qiantong Xu and Fenglu Hong and Bo Li and Changran Hu and Zhengyu Chen and Jian Zhang},
      year={2023},
      eprint={2305.16504},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{hendrycks2021measuring,
  title={Measuring Coding Challenge Competence With APPS},
  author={Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}


@inproceedings{pasupat2015compositional,
  title={Compositional Semantic Parsing on Semi-Structured Tables},
  author={Pasupat, Panupong and Liang, Percy},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1470--1480},
  year={2015}
}

@inproceedings{yang2018hotpotqa,
  title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William and Salakhutdinov, Ruslan and Manning, Christopher D},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2369--2380},
  year={2018}
}

@inproceedings{hendrycks2021math,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{shridhar2020alfworld,
  title={ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
  author={Shridhar, Mohit and Yuan, Xingdi and Cote, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@misc{zeng2023agenttuning,
      title={AgentTuning: Enabling Generalized Agent Abilities for LLMs},
      author={Aohan Zeng and Mingdao Liu and Rui Lu and Bowen Wang and Xiao Liu and Yuxiao Dong and Jie Tang},
      year={2023},
      eprint={2310.12823},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{OpenOrca,
  title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
  author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}

@software{epfmgtrn,
  author       = {Alejandro Hernández Cano  and
                  Matteo Pagliardini  and
                  Andreas Köpf  and
                  Kyle Matoba  and
                  Amirkeivan Mohtashami  and
                  Xingyao Wang  and
                  Olivia Simin Fan  and
                  Axel Marmet  and
                  Deniz Bayazit  and
                  Igor Krawczuk  and
                  Zeming Chen  and
                  Francesco Salvi  and
                  Antoine Bosselut  and
                  Martin Jaggi},
  title        = {epfLLM Megatron-LLM},
  year         = 2023,
  url          = {https://github.com/epfLLM/Megatron-LLM}
}
@article{wang2023survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={arXiv preprint arXiv:2308.11432},
  year={2023}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{chen2023measuring,
  title={Measuring and improving chain-of-thought reasoning in vision-language models},
  author={Chen, Yangyi and Sikka, Karan and Cogswell, Michael and Ji, Heng and Divakaran, Ajay},
  journal={arXiv preprint arXiv:2309.04461},
  year={2023}
}


@article{fischer2023reflective,
  title={Reflective Linguistic Programming (RLP): A Stepping Stone in Socially-Aware AGI (SocialAGI)},
  author={Fischer, Kevin A},
  journal={arXiv preprint arXiv:2305.12647},
  year={2023}
}
@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2023}
}


@article{zhu2023ghost,
  title={Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@inproceedings{lee2022coauthor,
  title={Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities},
  author={Lee, Mina and Liang, Percy and Yang, Qian},
  booktitle={Proceedings of the 2022 CHI conference on human factors in computing systems},
  pages={1--19},
  year={2022}
}


@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@inproceedings{hendrycks2020measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{zheng2023judging,
  title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={arXiv preprint arXiv:2306.05685},
  year={2023}
}

@article{weng2023prompt,
  title   = "LLM-powered Autonomous Agents",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2023",
  month   = "Jun",
  url     = "https://lilianweng.github.io/posts/2023-06-23-agent/"
}

@article{kim2023language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={arXiv preprint arXiv:2303.17491},
  year={2023}
}

@inproceedings{Wang2022ScienceWorldIY,
  title={ScienceWorld: Is your Agent Smarter than a 5th Grader?},
  author={Ruoyao Wang and Peter Alexander Jansen and Marc-Alexandre C{\^o}t{\'e} and Prithviraj Ammanabrolu},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:247451124}
}

@misc{sharegpt_dataset,
  author       = {Anonymous},
  title        = {ShareGPT Dataset},
  year         = {2023},
  howpublished = {\url{https://hf.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/blob/main/ShareGPT_V3_unfiltered_cleaned_split_no_imsorry.json}},
  note         = {A dataset containing multi-turn conversations between human and LLM assistant.}
}

@misc{sharegpt4_dataset,
  author       = {OpenChat},
  title        = {ShareGPT Dataset},
  year         = {2023},
  howpublished = {\url{https://hf.co/datasets/openchat/openchat_sharegpt_v3/blob/main/sharegpt_gpt4.json}},
  note         = {A dataset containing multi-turn conversations between human and LLM assistants. It is filtered to contain data only from GPT-4.}
}


@misc{capybara_dataset,
  author       = {LDJnr},
  title        = {CapyBara Dataset},
  year         = {2023},
  howpublished = {\url{https://hf.co/datasets/LDJnr/Verified-Camel}, \url{https://hf.co/datasets/LDJnr/Pure-Dove}, \url{https://hf.co/datasets/LDJnr/LessWrong-Amplify-Instruct}},
  note         = {A dataset focusing on reasoning in multi-turn conversations.}
}

@misc{yang2024llm,
      title={If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents}, 
      author={Ke Yang and Jiateng Liu and John Wu and Chaoqi Yang and Yi R. Fung and Sha Li and Zixuan Huang and Xu Cao and Xingyao Wang and Yiquan Wang and Heng Ji and Chengxiang Zhai},
      year={2024},
      eprint={2401.00812},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tiobe,
  author       = {{TIOBE Index}},
  title        = {TIOBE Index},
  year         = {2024},
  howpublished = {\url{https://www.tiobe.com/tiobe-index/}, Accessed at Jan 23rd, 2024},
  note         = {The TIOBE Programming Community index is an indicator of the popularity of programming languages. The index is updated once a month. The ratings are based on the number of skilled engineers world-wide, courses and third party vendors.}
}

@article{schaeffer2023emergent,
  title={Are emergent abilities of Large Language Models a mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}

@software{jupyter_kernel_gateway,
author = {{Jupyter Team}},
license = {3-Clause BSD},
title = {Jupyter Kernel GateWay},
url = {https://github.com/jupyter-server/kernel_gateway},
year={2024}
}

@article{eloundou2023gpts,
  title={Gpts are gpts: An early look at the labor market impact potential of large language models},
  author={Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  journal={arXiv preprint arXiv:2303.10130},
  year={2023}
}

@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022}
}

@article{surismenon2023vipergpt,
    title={ViperGPT: Visual Inference via Python Execution for Reasoning},
    author={D\'idac Sur\'is and Sachit Menon and Carl Vondrick},
    journal={Proceedings of IEEE International Conference on Computer Vision (ICCV)},
    year={2023}
}


@inproceedings{wang-etal-2023-code4struct,
    title = "{C}ode4{S}truct: Code Generation for Few-Shot Event Structure Prediction",
    author = "Wang, Xingyao  and
      Li, Sha  and
      Ji, Heng",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.202",
    doi = "10.18653/v1/2023.acl-long.202",
    pages = "3640--3663",
    abstract = "Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. We observe that semantic structures can be conveniently translated into code and propose Code4Struct to leverage such text-to-structure translation capability to tackle structured prediction tasks. As a case study, we formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code. This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance and type annotation to introduce external knowledge or add constraints. We show that, with sufficient in-context examples, formulating EAE as a code generation problem is advantageous over using variants of text-based prompts. Despite only using 20 training event instances for each event type, Code4Struct is comparable to supervised models trained on 4,202 instances and outperforms current state-of-the-art (SOTA) trained on 20-shot data by 29.5{\%} absolute F1. Code4Struct can use 10-shot training data from a sibling event type to predict arguments for zero-resource event types and outperforms the zero-shot baseline by 12{\%} absolute F1.",
}

@INPROCEEDINGS{progprompt,
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={ProgPrompt: Generating Situated Robot Task Plans using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={11523-11530},
  doi={10.1109/ICRA48891.2023.10161317}}

@article{tang2024prioritizing,
  title={Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science},
  author={Tang, Xiangru and Jin, Qiao and Zhu, Kunlun and Yuan, Tongxin and Zhang, Yichi and Zhou, Wangchunshu and Qu, Meng and Zhao, Yilun and Tang, Jian and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2402.04247},
  year={2024}
}  

@misc{yang2024unified,
      title={Towards Unified Alignment Between Agents, Humans, and Environment}, 
      author={Zonghan Yang and An Liu and Zijun Liu and Kaiming Liu and Fangzhou Xiong and Yile Wang and Zeyuan Yang and Qingyuan Hu and Xinrui Chen and Zhenhe Zhang and Fuwen Luo and Zhicheng Guo and Peng Li and Yang Liu},
      year={2024},
      eprint={2402.07744},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@incollection{boerner2023access,
  title={Access: Advancing innovation: Nsf’s advanced cyberinfrastructure coordination ecosystem: Services \& support},
  author={Boerner, Timothy J and Deems, Stephen and Furlani, Thomas R and Knuth, Shelley L and Towns, John},
  booktitle={Practice and Experience in Advanced Research Computing},
  pages={173--176},
  year={2023}
}

@article{hong2023metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}


@article{opencodeinterpreter,
    title={OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement},
    author={Tianyu Zheng and Ge Zhang and Tianhao Shen and Xueling Liu and Bill Yuchen Lin and Jie Fu and Wenhu Chen and Xiang Yue},
    journal={https://arxiv.org/abs/2402.14658},
    year={2024},
}

@misc{hong2024data,
      title={Data Interpreter: An LLM Agent For Data Science}, 
      author={Sirui Hong and Yizhang Lin and Bang Liu and Bangbang Liu and Binhao Wu and Danyang Li and Jiaqi Chen and Jiayi Zhang and Jinlin Wang and Li Zhang and Lingyao Zhang and Min Yang and Mingchen Zhuge and Taicheng Guo and Tuo Zhou and Wei Tao and Wenyi Wang and Xiangru Tang and Xiangtao Lu and Xiawu Zheng and Xinbing Liang and Yaying Fei and Yuheng Cheng and Zongze Xu and Chenglin Wu},
      year={2024},
      eprint={2402.18679},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{yang2024intercode,
  title={Intercode: Standardizing and benchmarking interactive coding with execution feedback},
  author={Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}